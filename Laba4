from google.colab import drive
drive.mount ('/content/drive')

import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

plt.figure(figsize=(10,10))
def GetImg(path):
  test_img = Image.open(path)
  test_img = test_img.resize((24, 24))
  plt.subplot(3,9,i)
  # test_img = test_img.convert('L')
  plt.imshow(test_img, cmap = "gray")
  test_x = np.array(test_img, np.float32)
  test_x = test_x.reshape([-1, 576]) / 255.0
  return test_x

pathEyes = '/content/drive/MyDrive/Eyes/'
pathLips = '/content/drive/MyDrive/Lips/'
pathNoses = '/content/drive/MyDrive/Nose/'

x_train = []
y_train = []

for i in range(1,6):
  x_train.append(GetImg(pathEyes + str(i) +'.png')[0])
  y_train.append(0)

for i in range(1,6):
  x_train.append(GetImg(pathLips + str(i) +'.png')[0])
  y_train.append(1)

for i in range(1,6):
  x_train.append(GetImg(pathNoses + str(i) +'.png')[0])
  y_train.append(2)

x_test = []
y_test = []
images = []

for i in range(6,9):
  x_test.append(GetImg(pathEyes + str(i) +'.png')[0])
  y_test.append(0)
  test_img = Image.open(pathEyes + str(i) +'.png')
  images.append(test_img.resize((24, 24)))

for i in range(6,9):
  x_test.append(GetImg(pathLips + str(i) +'.png')[0])
  y_test.append(1)
  test_img = Image.open(pathLips + str(i) +'.png')
  images.append(test_img.resize((24, 24)))

for i in range(6,7):
  x_test.append(GetImg(pathNoses + str(i) +'.png')[0])
  y_test.append(2)
  test_img = Image.open(pathNoses + str(i) +'.png')
  images.append(test_img.resize((24, 24)))

print(len(images))

import random
import numpy as np

INPUT_DIM = 576
OUT_DIM = 3
H_DIM = 10

def relu(t):
    return np.maximum(t, 0)

def softmax_batch(t):
    out = np.exp(t)
    return out / np.sum(out, axis=1, keepdims=True)

def sparse_cross_entropy_batch(z, y):
    return -np.log(np.array([z[j, y[j]] for j in range(len(y))]))


def to_full_batch(y, num_classes):
    y_full = np.zeros((len(y), num_classes))
    for j, yj in enumerate(y):
        y_full[j, yj] = 1
    return y_full

def relu_deriv(t):
    return (t >= 0).astype(float)

dataset = [(x_train[i].reshape(1,-1), y_train[i]) for i in range(len(x_train))]

W1 = np.random.rand(INPUT_DIM, H_DIM)
b1 = np.random.rand(1, H_DIM)
W2 = np.random.rand(H_DIM, OUT_DIM)
b2 = np.random.rand(1, OUT_DIM)

W1 = (W1 - 0.5) * 2 * np.sqrt(1/INPUT_DIM)
b1 = (b1 - 0.5) * 2 * np.sqrt(1/INPUT_DIM)
W2 = (W2 - 0.5) * 2 * np.sqrt(1/H_DIM)
b2 = (b2 - 0.5) * 2 * np.sqrt(1/H_DIM)

ALPHA = 0.001
NUM_EPOCHS = 3000
BATCH_SIZE = 5

loss_arr = []

for ep in range(NUM_EPOCHS):
    random.shuffle(dataset)
    for i in range(len(dataset) // BATCH_SIZE):

      batch_x, batch_y = zip(*dataset[i*BATCH_SIZE : i*BATCH_SIZE+BATCH_SIZE])
      x = np.concatenate(batch_x, axis=0)
      y = np.array(batch_y)

      # Forward
      t1 = x @ W1 + b1
      h1 = relu(t1)
      t2 = h1 @ W2 + b2
      z = softmax_batch(t2)
      E = np.sum(sparse_cross_entropy_batch(z, y))

      # Backward
      y_full = to_full_batch(y, OUT_DIM)
      dE_dt2 = z - y_full
      dE_dW2 = h1.T @ dE_dt2
      dE_db2 = np.sum(dE_dt2, axis=0, keepdims=True)
      dE_dh1 = dE_dt2 @ W2.T
      dE_dt1 = dE_dh1 * relu_deriv(t1)
      dE_dW1 = x.T @ dE_dt1
      dE_db1 = np.sum(dE_dt1, axis=0, keepdims=True)

      # Update
      W1 = W1 - ALPHA * dE_dW1
      b1 = b1 - ALPHA * dE_db1
      W2 = W2 - ALPHA * dE_dW2
      b2 = b2 - ALPHA * dE_db2

    print('Error on epoch ' + str(ep) + ' : ' + str(E))
    loss_arr.append(E)
    if (E < 0.005):
      break

def predict(x):
    t1 = x @ W1 + b1
    h1 = relu(t1)
    t2 = h1 @ W2 + b2
    z = softmax_batch(t2)
    return z

def pred(x):
    t1 = x @ W1 + b1
    h1 = relu(t1)
    t2 = h1 @ W2 + b2
    print(f"Y before softmax: {t2}")
    z = softmax_batch(t2)
    print(f"Y after softmax: {z}")
    s = [0 for i in range(len(z.reshape(-1,1)))]
    s[list(z[0]).index(np.array(z[0]).max())] = 1
    print(s)
    print(f"Следовательно y => {list(z[0]).index(np.array(z[0]).max())}")
    return list(z[0]).index(np.array(z[0]).max())

def calc_accuracy():
    correct = 0
    for x, y in dataset:
        z = predict(x)
        y_pred = np.argmax(z)
        if y_pred == y:
            correct += 1
    acc = correct / len(dataset)
    return acc

accuracy = calc_accuracy()
print("Accuracy:", accuracy)

import matplotlib.pyplot as plt
plt.plot(loss_arr)
plt.show()

predictions = []

for i in range(len(x_test)):
  predictions.append(pred(x_test[i]))

print(len(predictions))
print(predictions)

plt.figure(figsize=(10,10))

for i in range(len(images)):
  plt.subplot(1,8,i+1)
  if predictions[i] == 0:
    plt.title('Глаз')
  elif predictions[i] == 1:
    plt.title('Губы')
  else:
    plt.title('Нос')
  plt.imshow(images[i], cmap = "gray")

countErrors = 0
for i in range(len(predictions)):
  if predictions[i] != y_test[i]:
    countErrors += 1

print('Точность на тестовой выборке: ' + str(round(1 - (countErrors / len(predictions)), 2)))
